#### Thesis
###### Towards foundation model for viral diseases.
Viral diseases have had a significant global impact, affecting millions of people worldwide. Estimating the potential number of positive cases is crucial for controlling disease spread and allocating necessary resources effectively. However, in the early stages of an outbreak, limited data availability poses significant challenges for accurate estimation. Additionally, employing individual models for each disease in specific regions proves less efficient. This work aims to train a foundation model on viral diseases, enabling estimation of positive cases during outbreaks and for existing diseases. Several existing foundation models are trained on different datasets spanning various domains. These models cannot adapt to the specific characteristics of viral disease related data. These models operate in a channel-independent manner, thus failing to assess the interactions among different variables. Yet, variables such as the number of affected and vaccinated cases are pivotal in enhancing the results within the domain of viral diseases. This endeavor seeks to develop a domain-specific foundation model tailored specifically for viral diseases, adapted to the unique data characteristics. 


Foundation models
	Several state of the art deep learning models for time series [TimeMixer, Timesnet, iTransformer, PatchTST and others] employ model per dataset scheme where the model is trained and tested on the sections of the same series. Specifically, there is a split point in the series. The data before the split point is considered as train set and data after the split point is considered as test set. The train and test set both come from the same series and represent the statistical properties of that series. Therefore, the model trained for that series may not show satisfactory results for another series. However, in cases of pandemic and viral diseases, we may lack sufficient training data in the initial days of disease spread. In these cases, utilizing a foundation model pretrained on sufficient time series data may allow to get better results for pandemic and viral diseases with finetuning. For the purpose, our goal is to design a domain specific foundation model for pandemic and viral diseases.
	Foundation models of time series can be divided into two types. Recent methods have utilized LLM pretrained on text and finetuned on time series modality. These methods have shown various ways to efficiently finetune the network and improve time series exploration. The other type pretrains the foundation from scratch on time series modality. These methods require pretraining on sufficient time series datasets. Pretraining foundation models for time series data poses several challenges. Each time series has different characteristics like number of channels, seasonality, trend, and frequency. The foundation model should be trained on the diverse datasets. 
	
Several foundation models like TimeGPT, TimesFM and others have pretrained in channel independent manner therefore the influence of exogenous variables on target variable is not incorporated. Some methods like PatchTST have shown improved results with channel independence on certain datasets and showed that channel mixing may give lower results due to noise. However, in case of pandemic and viral diseases, the exogenous variables like 




